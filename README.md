# ml4nlp
_my slides for ml4nlp seminar by Prof. Klakow_

> [!NOTE]
> In the slides, I discuss the pretraining of large language models. I discuss scaling laws, the evolution of the GPT models, data needed to train such models and commonly used architectures. I am writing an accompanying term paper required for the seminal, and will be using explanations from there to give explanations here as well. More content coming soon ‚ù§

